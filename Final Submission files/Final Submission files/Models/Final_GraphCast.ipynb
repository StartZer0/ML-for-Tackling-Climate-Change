{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1zvvCktbC5PfrkOQH33yOb3LzEFEGwLEG","timestamp":1742371555152}],"machine_shape":"hm","gpuType":"L4","mount_file_id":"1J_R3gnn8LFsNpjQrY9na-gw4qxnSo-ec","authorship_tag":"ABX9TyOQnSsapRMoLUmc+pxn0lTI"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["!pip install torch-geometric"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2b08JWEet3Hm","executionInfo":{"status":"ok","timestamp":1742388256315,"user_tz":0,"elapsed":4017,"user":{"displayName":"Climatechange","userId":"11406078412181177088"}},"outputId":"3df0d28d-0bd3-460c-9d29-fb819ffa8dd2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting torch-geometric\n","  Downloading torch_geometric-2.6.1-py3-none-any.whl.metadata (63 kB)\n","\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/63.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.1/63.1 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (3.11.13)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (2024.10.0)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (3.1.6)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (2.0.2)\n","Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (5.9.5)\n","Requirement already satisfied: pyparsing in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (3.2.1)\n","Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (2.32.3)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (4.67.1)\n","Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (2.6.1)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (1.3.2)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (25.3.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (1.5.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (6.1.0)\n","Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (0.3.0)\n","Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (1.18.3)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch-geometric) (3.0.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric) (3.4.1)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric) (2.3.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric) (2025.1.31)\n","Downloading torch_geometric-2.6.1-py3-none-any.whl (1.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m19.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: torch-geometric\n","Successfully installed torch-geometric-2.6.1\n"]}]},{"cell_type":"code","source":["import os\n","import numpy as np\n","import xarray as xr\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torch.utils.data import Dataset, DataLoader\n","from torch_geometric.nn import MessagePassing\n","from torch_geometric.utils import add_self_loops\n","from torch_geometric.nn import GCNConv\n","import matplotlib.pyplot as plt\n","from tqdm import tqdm\n","import pandas as pd\n","from sklearn.metrics import mean_squared_error, mean_absolute_error\n","\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","print(f\"Using device: {device}\")\n","\n","# Define Constants\n","INPUT_DAYS = 60   # Historical input\n","OUTPUT_DAYS = 14  # Forecasting horizon (10,14,44)\n","NUM_VARIABLES = 10 # Match dataset variables\n","GRID_SIZE = 14  # 14x14 grid (196 regions)\n","VARIABLE_NAMES = ['z500', 't850', 'e', 'evavt', 'lai_lv', 'pev', 'swvl2', 'swvl3', 't2m', 'tp']"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lslE_HxTcSZQ","executionInfo":{"status":"ok","timestamp":1742388647888,"user_tz":0,"elapsed":12763,"user":{"displayName":"Climatechange","userId":"11406078412181177088"}},"outputId":"6f7f85dd-8a91-4017-dc2e-f340a9bb8158"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Using device: cuda\n"]}]},{"cell_type":"code","source":["# Data Loading and Processing\n","class ClimateDataset(Dataset):\n","    def __init__(self, filename, input_days=INPUT_DAYS, output_days=OUTPUT_DAYS):\n","        self.data = xr.open_dataset(filename)\n","        self.input_days = input_days\n","        self.output_days = output_days\n","        self.num_timesteps = len(self.data.time)\n","        self.valid_indices = list(range(self.num_timesteps - (input_days + output_days) + 1))\n","\n","    def __len__(self):\n","        return len(self.valid_indices)\n","\n","    def __getitem__(self, idx):\n","        start_idx = self.valid_indices[idx]\n","        if start_idx + self.input_days + self.output_days > self.num_timesteps:\n","            return None\n","        input_data = np.stack([self.data[var].isel(time=slice(start_idx, start_idx + self.input_days)).values for var in VARIABLE_NAMES], axis=0)\n","        target_data = np.stack([self.data[var].isel(time=slice(start_idx + self.input_days, start_idx + self.input_days + self.output_days)).values for var in VARIABLE_NAMES], axis=0)\n","        return {'input': torch.FloatTensor(input_data), 'target': torch.FloatTensor(target_data)}"],"metadata":{"id":"CwAoRwVpcU-z"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Graph Construction\n","def create_grid_graph(height, width):\n","    edge_list = []\n","    for h in range(height):\n","        for w in range(width):\n","            node_idx = h * width + w\n","            if w < width - 1: edge_list.append([node_idx, node_idx + 1])\n","            if h < height - 1: edge_list.append([node_idx, node_idx + width])\n","    edge_index = torch.tensor(edge_list).t().contiguous()\n","    return add_self_loops(edge_index)[0]\n","\n","# Graph Neural Network Layers\n","class GraphCastLayer(MessagePassing):\n","    def __init__(self, in_channels, out_channels):\n","        super(GraphCastLayer, self).__init__(aggr='add')\n","        self.lin = nn.Linear(in_channels, out_channels)\n","\n","    def forward(self, x, edge_index):\n","        return self.propagate(edge_index, x=self.lin(x))"],"metadata":{"id":"cQu5ecRUcW7J"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class GraphCast(nn.Module):\n","    def __init__(self):\n","        super(GraphCast, self).__init__()\n","        self.encoder = nn.Conv2d(NUM_VARIABLES * INPUT_DAYS, 128, kernel_size=3, padding=1)\n","        self.graph_layer = GCNConv(128, 128)\n","        self.temporal_attention = nn.MultiheadAttention(embed_dim=128, num_heads=8, batch_first=True)\n","        self.decoder = nn.Conv2d(128, NUM_VARIABLES, kernel_size=3, padding=1)\n","        self.edge_index = create_grid_graph(GRID_SIZE, GRID_SIZE).to(device)\n","\n","    def forward(self, x):\n","        batch_size = x.size(0)\n","        x = x.reshape(batch_size, NUM_VARIABLES * INPUT_DAYS, GRID_SIZE, GRID_SIZE)\n","        x = self.encoder(x)\n","        x_graph = x.permute(0, 2, 3, 1).reshape(-1, 128)\n","        x_graph = self.graph_layer(x_graph, self.edge_index)\n","        x = x_graph.reshape(batch_size, GRID_SIZE, GRID_SIZE, 128)\n","        x_temp = x.reshape(batch_size, GRID_SIZE * GRID_SIZE, 128)\n","        x_temp, _ = self.temporal_attention(x_temp, x_temp, x_temp)\n","        x = x_temp.reshape(batch_size, 128, GRID_SIZE, GRID_SIZE)\n","        x = self.decoder(x)\n","        x = x.unsqueeze(2).repeat(1, 1, OUTPUT_DAYS, 1, 1)\n","        return x\n"],"metadata":{"id":"mhKj8XVlcbT9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Training and Evaluation Functions\n","def train_one_epoch(model, train_loader, optimizer, criterion):\n","    model.train()\n","    total_loss = 0\n","    for batch in tqdm(train_loader, desc=\"Training\"):\n","        optimizer.zero_grad()\n","        outputs = model(batch['input'].to(device))\n","        loss = criterion(outputs, batch['target'].to(device))\n","        loss.backward()\n","        optimizer.step()\n","        total_loss += loss.item()\n","    return total_loss / len(train_loader)\n","\n","def evaluate(model, val_loader, criterion):\n","    model.eval()\n","    total_loss = 0\n","    with torch.no_grad():\n","        for batch in tqdm(val_loader, desc=\"Validation\"):\n","            outputs = model(batch['input'].to(device))\n","            loss = criterion(outputs, batch['target'].to(device))\n","            total_loss += loss.item()\n","    return total_loss / len(val_loader)\n","\n","# Train the Model\n","def train_model(model, train_loader, val_loader, num_epochs=30):\n","    optimizer = optim.Adam(model.parameters(), lr=0.001)\n","    criterion = nn.SmoothL1Loss()  # Huber loss for better robustness\n","    best_val_loss = float('inf')\n","    for epoch in range(num_epochs):\n","        print(f\"Epoch {epoch+1}/{num_epochs}\")\n","        train_loss = train_one_epoch(model, train_loader, optimizer, criterion)\n","        val_loss = evaluate(model, val_loader, criterion)\n","        print(f\"Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}\")\n","        if val_loss < best_val_loss:\n","            best_val_loss = val_loss\n","            torch.save(model.state_dict(), 'best_model.pth')\n","    return best_val_loss"],"metadata":{"id":"AZ6jqM18cgzN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Run the Training Pipeline\n","train_file = '/content/drive/MyDrive/drought_data/processed/drought_train_normalized_imp.nc'\n","val_file = '/content/drive/MyDrive/drought_data/processed/drought_val_normalized_imp.nc'\n","train_dataset = ClimateDataset(train_file)\n","val_dataset = ClimateDataset(val_file)\n","train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True)\n","val_loader = DataLoader(val_dataset, batch_size=4, shuffle=False)\n","model = GraphCast().to(device)\n","best_val_loss = train_model(model, train_loader, val_loader)\n","print(f\"Best Validation Loss: {best_val_loss:.4f}\")"],"metadata":{"id":"pJKIvCvUck0o"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def calculate_rmse(model_path, val_loader):\n","    \"\"\"\n","    Calculates RMSE for each variable from the trained model.\n","    \"\"\"\n","    model = GraphCast().to(device)\n","    model.load_state_dict(torch.load(model_path))\n","    model.eval()\n","\n","    total_rmse = {var: 0.0 for var in VARIABLE_NAMES}\n","    count = 0\n","\n","    with torch.no_grad():\n","        for batch in tqdm(val_loader, desc=\"Evaluating RMSE\"):\n","            inputs = batch['input'].to(device)\n","            targets = batch['target'].to(device)\n","            outputs = model(inputs)\n","            outputs = outputs.cpu().numpy()\n","            targets = targets.cpu().numpy()\n","\n","            for i, var_name in enumerate(VARIABLE_NAMES):\n","                rmse = np.sqrt(np.mean((outputs[:, i, :, :, :] - targets[:, i, :, :, :]) ** 2))\n","                total_rmse[var_name] += rmse\n","\n","            count += 1\n","\n","    # Average RMSE over batches\n","    for var_name in VARIABLE_NAMES:\n","        total_rmse[var_name] /= count\n","\n","    # Print RMSE values\n","    print(\"\\nRMSE for each variable:\")\n","    for var_name, rmse in total_rmse.items():\n","        print(f\"{var_name}: {rmse:.4f}\")\n","\n","    return total_rmse\n","\n","# Compute RMSE from Best Model\n","calculate_rmse('/content/drive/MyDrive/Best_models/graphcast_30epoch_10days.pth', val_loader)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vHCTRD6t4RpU","executionInfo":{"status":"ok","timestamp":1742388732000,"user_tz":0,"elapsed":9344,"user":{"displayName":"Climatechange","userId":"11406078412181177088"}},"outputId":"879dfeb6-e433-4e86-f579-ec3df21df514"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Evaluating RMSE: 100%|██████████| 252/252 [00:08<00:00, 31.24it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","RMSE for each variable:\n","z500: 0.2718\n","t850: 0.3970\n","e: 1.1004\n","evavt: 2.1707\n","lai_lv: 0.3907\n","pev: 1.1536\n","swvl2: 0.3972\n","swvl3: 0.3699\n","t2m: 0.0868\n","tp: 2.1686\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"execute_result","data":{"text/plain":["{'z500': np.float32(0.27178913),\n"," 't850': np.float32(0.3969592),\n"," 'e': np.float32(1.100355),\n"," 'evavt': np.float32(2.17069),\n"," 'lai_lv': np.float32(0.39069992),\n"," 'pev': np.float32(1.1536137),\n"," 'swvl2': np.float32(0.39717546),\n"," 'swvl3': np.float32(0.36988273),\n"," 't2m': np.float32(0.086847365),\n"," 'tp': np.float32(2.1685805)}"]},"metadata":{},"execution_count":10}]},{"cell_type":"code","source":["import os\n","import pandas as pd\n","import numpy as np\n","import torch\n","import matplotlib.pyplot as plt\n","from pathlib import Path\n","\n","\n","def load_normalization_parameters(climatology_dir=\"/content/drive/MyDrive/climatology\"):\n","    \"\"\"\n","    Load normalization parameters.\n","    \"\"\"\n","    era5_mean = pd.read_csv(os.path.join(climatology_dir, \"era5_mean.csv\"))\n","    era5_sigma = pd.read_csv(os.path.join(climatology_dir, \"era5_sigma.csv\"))\n","    lra5_mean = pd.read_csv(os.path.join(climatology_dir, \"lra5_mean.csv\"))\n","    lra5_sigma = pd.read_csv(os.path.join(climatology_dir, \"lra5_sigma.csv\"))\n","\n","    era5_mean_dict = dict(zip(era5_mean[\"param\"], era5_mean[\"mean\"]))\n","    era5_sigma_dict = dict(zip(era5_sigma[\"param\"], era5_sigma[\"sigma\"]))\n","    lra5_mean_dict = dict(zip(lra5_mean[\"param\"], lra5_mean[\"mean\"]))\n","    lra5_sigma_dict = dict(zip(lra5_sigma[\"param\"], lra5_sigma[\"sigma\"]))\n","\n","    variable_mapping = {\n","        'z500': 'z-500', 't850': 't-850', 't2m': 't2m', 'swvl3': 'swvl3',\n","        'tp': 'tp', 'pev': 'pev', 'swvl2': 'swvl2', 'e': 'e',\n","        'evavt': 'evavt', 'lai_lv': 'lai_lv'\n","    }\n","\n","    return {\n","        'era5_mean': era5_mean_dict, 'era5_sigma': era5_sigma_dict,\n","        'lra5_mean': lra5_mean_dict, 'lra5_sigma': lra5_sigma_dict,\n","        'variable_mapping': variable_mapping\n","    }\n","\n","def get_normalization_params_for_variable(var_name, norm_params):\n","    \"\"\"\n","    Retrieve normalization parameters for a given variable.\n","    \"\"\"\n","    era5_mean_dict = norm_params['era5_mean']\n","    era5_sigma_dict = norm_params['era5_sigma']\n","    lra5_mean_dict = norm_params['lra5_mean']\n","    lra5_sigma_dict = norm_params['lra5_sigma']\n","    variable_mapping = norm_params['variable_mapping']\n","\n","    if var_name in variable_mapping:\n","        mapped_var = variable_mapping[var_name]\n","        if mapped_var in era5_mean_dict:\n","            return era5_mean_dict[mapped_var], era5_sigma_dict[mapped_var]\n","        elif mapped_var in lra5_mean_dict:\n","            return lra5_mean_dict[mapped_var], lra5_sigma_dict[mapped_var]\n","\n","    if var_name in lra5_mean_dict:\n","        return lra5_mean_dict[var_name], lra5_sigma_dict[var_name]\n","\n","    print(f\"Warning: No normalization parameters found for {var_name}\")\n","    return None, None\n","\n","def denormalize_tensor(normalized_data, variable_names, norm_params=None):\n","    \"\"\"\n","    Denormalize a tensor using climatology parameters.\n","    \"\"\"\n","    if norm_params is None:\n","        norm_params = load_normalization_parameters()\n","\n","    is_tensor = torch.is_tensor(normalized_data)\n","    if is_tensor:\n","        data_np = normalized_data.detach().cpu().numpy()\n","    else:\n","        data_np = normalized_data.copy()\n","\n","    denormalized_data = np.zeros_like(data_np)\n","\n","    for i, var_name in enumerate(variable_names):\n","        mean, sigma = get_normalization_params_for_variable(var_name, norm_params)\n","        if mean is not None and sigma is not None:\n","            denormalized_data[:, i] = data_np[:, i] * sigma + mean\n","\n","    return torch.tensor(denormalized_data, device=normalized_data.device, dtype=normalized_data.dtype) if is_tensor else denormalized_data\n","\n","def compute_denormalized_rmse(model, val_loader, climatology_dir):\n","    \"\"\"\n","    Compute RMSE on denormalized data.\n","    \"\"\"\n","    model.eval()\n","    norm_params = load_normalization_parameters(climatology_dir)\n","    total_rmse = {var: 0.0 for var in VARIABLE_NAMES}\n","    count = 0\n","\n","    with torch.no_grad():\n","        for batch in val_loader:\n","            inputs = batch['input'].to(device)\n","            targets = batch['target'].to(device)\n","            outputs = model(inputs)\n","            outputs = denormalize_tensor(outputs, VARIABLE_NAMES, norm_params)\n","            targets = denormalize_tensor(targets, VARIABLE_NAMES, norm_params)\n","\n","            outputs = outputs.cpu().numpy()\n","            targets = targets.cpu().numpy()\n","\n","            for i, var_name in enumerate(VARIABLE_NAMES):\n","                rmse = np.sqrt(np.mean((outputs[:, i, :, :, :] - targets[:, i, :, :, :]) ** 2))\n","                total_rmse[var_name] += rmse\n","            count += 1\n","\n","    for var_name in VARIABLE_NAMES:\n","        total_rmse[var_name] /= count\n","\n","    print(\"\\nDenormalized RMSE Per Variable:\")\n","    for var_name, rmse in total_rmse.items():\n","        print(f\"  {var_name}: {rmse:.6f}\")\n","\n","    overall_rmse = np.mean(list(total_rmse.values()))\n","    print(f\"\\nOverall Mean RMSE: {overall_rmse:.6f}\")\n","\n","    return total_rmse, overall_rmse\n","\n","# Compute Denormalized RMSE for GraphCast\n","best_model_path = \"/content/drive/MyDrive/Best_models/graphcast_30epoch_44days.pth\"\n","model.load_state_dict(torch.load(best_model_path, map_location=device))\n","compute_denormalized_rmse(model, val_loader, climatology_dir=\"/content/drive/MyDrive/climatology\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pohMO4hSaeYQ","executionInfo":{"status":"ok","timestamp":1742391784524,"user_tz":0,"elapsed":7198,"user":{"displayName":"Climatechange","userId":"11406078412181177088"}},"outputId":"127b59a9-11d2-4437-b0e0-27f51f86ee11"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Denormalized RMSE Per Variable:\n","  z500: 103.674919\n","  t850: 7.000451\n","  e: 0.000958\n","  evavt: 0.000464\n","  lai_lv: 0.318253\n","  pev: 0.005300\n","  swvl2: 0.068230\n","  swvl3: 0.067477\n","  t2m: 17.887964\n","  tp: 0.006203\n","\n","Overall Mean RMSE: 12.903023\n"]},{"output_type":"execute_result","data":{"text/plain":["({'z500': np.float32(103.67492),\n","  't850': np.float32(7.0004506),\n","  'e': np.float32(0.0009583947),\n","  'evavt': np.float32(0.00046412705),\n","  'lai_lv': np.float32(0.3182531),\n","  'pev': np.float32(0.0052996804),\n","  'swvl2': np.float32(0.06823022),\n","  'swvl3': np.float32(0.06747739),\n","  't2m': np.float32(17.887964),\n","  'tp': np.float32(0.0062031457)},\n"," np.float32(12.903023))"]},"metadata":{},"execution_count":26}]}]}